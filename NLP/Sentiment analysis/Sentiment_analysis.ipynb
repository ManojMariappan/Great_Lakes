{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BW5-CN0I--cL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Flatten, Dense, TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWRVP11ygxLB"
   },
   "source": [
    "### Import The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rseUuY9I_EMJ",
    "outputId": "c9875dc9-ba07-489c-ce78-1b9b4ffe1005"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RauB9JmghBhS"
   },
   "source": [
    "### Padding Each Scentence to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wGwYeFar_o4m"
   },
   "outputs": [],
   "source": [
    "# Maxiumum sequence length 300\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = 300)\n",
    "X_test =  pad_sequences(X_test, maxlen = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IbylX52nKK1"
   },
   "source": [
    "### Shape of Features and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ecxGV-x-rLv"
   },
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBoGKUIH_wJV",
    "outputId": "779787ec-5181-403b-a0b5-1b13a3f0e8e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of review, number of words in each review in the Training Data\n",
      "(25000, 300)\n",
      "Number of review, number of words in each review in the Testing Data\n",
      "(25000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of review, number of words in each review in the Training Data\")\n",
    "print(X_train.shape)\n",
    "print(\"Number of review, number of words in each review in the Testing Data\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laSNXL-Z-uSY"
   },
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLDpeYhEnxNy",
    "outputId": "aab429e9-c3d6-475d-bed9-5dc1b2dd553c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labels in the Training Data\n",
      "(25000,)\n",
      "Number of Labels in the Training Data\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Labels in the Training Data\")\n",
    "print(y_train.shape)\n",
    "print(\"Number of Labels in the Training Data\")\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMd7HdGLoCmd"
   },
   "source": [
    "### Print value of any one feature and it's label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgHSfGVioNWO"
   },
   "source": [
    "#### Lets Check a Feature and label of a record with its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cvSKzZT_2PV",
    "outputId": "e37ab239-a35f-4bee-fa5a-f3a943dba028"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    1,   13, 1059,   14,   33,    6,\n",
       "       2181, 2824,   32,   13,   70,  135,    9,   51,    4,  609,   14,\n",
       "         20,  299,   46,   44,   17, 9287,   17, 4111, 2914,  886,    4,\n",
       "        229,   18, 6624,   45, 1162,  724,  231,    4, 3638,  227,    7,\n",
       "        281,    5,   60,   48,   25,   81,  563,  129, 1224,   11,    4,\n",
       "        519,    4,   22,    9,  131,   38, 1162,   15,   12,  218,   60,\n",
       "        163,   10,   10,    4,  114, 2290, 4660, 2243, 1230, 9771,  269,\n",
       "          8,  607,    6, 4660,   63, 1367,    6, 3732,    2,    4, 3732,\n",
       "        266,  103, 9771,    8,   79,   68,    2,  145, 9771, 2497,   98,\n",
       "         18,    2,    5,  732,   46,    8,  570,   98,   10,   10,  198,\n",
       "         44,   32,    4,   65,   50,    9,    4,  360,    9,  120,    4,\n",
       "        350,    2,    7, 2435, 1181,    2,   67,    2,    5,    2,    5,\n",
       "       2886, 4331,  206,  844,   33,   31,  213, 9771,    2,    6,    2,\n",
       "          2,    5, 3193, 1860,   19,    6, 3732, 1544,   23,  350,    7,\n",
       "         12,  422,  198,  208, 1230, 9771, 3193, 1860,    6,  232,   23,\n",
       "        350,    7,   35,    2,  387,   15,   30,  129, 3619,   18,   14,\n",
       "       3931,   78,   22], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoGwphARBEK1",
    "outputId": "a154986e-fa7c-412f-cafa-453860c62cea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg7PC7cR-2n_"
   },
   "source": [
    "- We can see the label of the entry 30 is 0 which is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFAwPsFuot3Y",
    "outputId": "b1afcce6-8dab-48bf-aa0e-571ad146435b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  93,    4, 1985, 6751,    5,   11,  359,    7,  766,   38,   29,\n",
       "       8929,    4,   86,  255,   29,   70,  103, 6518,    4,   85,  605,\n",
       "          9,    6,  601,  136,    7,    2,   11, 1445,   19, 4115,    5,\n",
       "         59,    9,  110, 1298,    6,   55,  729, 4094,  136,   16,  605,\n",
       "         46,    7,    4,  178,  310,    7, 1985, 2694, 1985, 1918,    4,\n",
       "       1362,  255,   17,   73,    4,   22,  127,   28,   45,  712,  151,\n",
       "         18,  813,    4,  167,   16, 1819,    4,   78,  759,   11,   18,\n",
       "          4, 1985,   33,  757,    4, 2526,  631, 3110,    4, 7166,    7,\n",
       "        844,   39,    4,   86,    2,   22,  951,    7,    4,    2, 2544,\n",
       "          2, 1775, 2573,    5,    4, 5367,    2,    7,   15,  598,  228,\n",
       "        603,  469,  525,   21,  110,   11,   45,  204, 5633, 2718,    5,\n",
       "       5444, 5987, 1985,  115, 6026,   12,    9,   31,    7,    4,    2,\n",
       "          5,   91, 3599,    7,    4,    2, 1985,  201,   19,    6,  114,\n",
       "        347,    2,   11,   45,  285,   21,    4, 3904, 4939, 1483,    4,\n",
       "        605,    2, 4381,    5,    2,  368,  268, 4651,    7,   14,   22,\n",
       "         81,   12,   57,    2,    5,  472,  198,    4,  310,  220,  316,\n",
       "       5953,   23,    4,   22,   28,  110,    4,   22, 2938,    6, 5496,\n",
       "          2,    5,  474, 2134,    4, 4506,  766, 1304,   23,    4,  899,\n",
       "          9, 6670,    4,   22,    2, 1985, 2694, 2544, 1985, 1918,    4,\n",
       "       1362,  255,   11,    4,  201,    5,   16,  434,  626,  159, 1985,\n",
       "       2694,    4,  277,    7, 1985,  115, 6026, 5117,    7,    4,    2,\n",
       "          2, 2555,   83,    4,  636,    7, 1985, 2694, 3991,    2, 2314,\n",
       "          7,   14, 1038,    6,  601,  310,    7,   14,  203,  115,   79,\n",
       "          6,  542,  766,    6,  404,  766,   62,   30,    4, 5444,  631,\n",
       "        310,   21,   11, 1875,   19,  631, 2576,    4,  631, 3110, 5498,\n",
       "       4352,    4,   20,   21,  101, 1875, 1101,  310,   62, 4589,    4,\n",
       "       2380,  310,   17,  617,   11, 5001,  315,    4, 4748,  999,  121,\n",
       "       1006,   16,    2], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[652]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhDefabKo2gF",
    "outputId": "d86824b2-7e55-4ef1-bdb0-837d7de3892d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[652]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GePLx2LX_FaY"
   },
   "source": [
    "- We can notice the label for the entry at 652 is 1 which is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aekN_Y57pGaj"
   },
   "source": [
    "### Creating Word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2lUjCDPBIq6",
    "outputId": "f37badbb-4d3a-4b52-e449-bcf273226af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0ePoaRbAE1f"
   },
   "source": [
    "#### lets ge the original value of the encoding from the word index dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHyAgSZSBVXJ",
    "outputId": "550b8a4e-55ad-4236-ee97-38b69eab8fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the was pace as they is underrated expression an was well why it when of number as on effects some has movie darling movie discuss fallen leaves of guy but nbc if super predictable minutes of territory far br actor to which what have people cannot man literally this of late of you it these her super for that interesting which makes i i of little crowd acid fame ex bryan looks in looked is acid really places is notably and of notably trying watch bryan in also were and those bryan whoever any but and to oscar some in known any i i series has an of their more it of hollywood it show of try and br structure starring and can and to and to nowadays waters without move they by come bryan and is and and to plague accurate film is notably park are try br that title series times ex bryan plague accurate is feel are try br so and episode for at man reynolds but as hugh do you "
     ]
    }
   ],
   "source": [
    "for encoding in X_train[30]:\n",
    "  for key, value in word_index.items():\n",
    "    if encoding == value:\n",
    "      print(key, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2viP7nqDGbl",
    "outputId": "c8c1d38a-ebfe-4dde-ab2b-07873238d55d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLR-35MPAr7w",
    "outputId": "16b4e14f-bbe9-48f7-8928-48b5018f4dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "way of regular pumbaa to this kids br storyline her all examined of how found all well watch pale of because ok it is group scenes br and this happening film financial to would it life touching is time sets passes scenes with ok some br of want house br regular con regular manage of ride found movie much of you end one if words old but soundtrack of going with originally of do bunch this but of regular they mention of walked hours per of moss br move or of how and you cheesy br of and magical and exist subtitles to of roof and br for complete making simple unfortunately won't not life this if i've studies initially to shoulder elevator regular best gillian that it by br of and to its ticket br of and regular original film is little top and this if dvd not of sadness garbo fellow of ok and blond to and truly goes taxi br as you people that even and to  series of house family seeing colin are of you one life of you remote is affection and to final wood of li storyline terrific are of shame it divine of you and regular con magical regular manage of ride found this of original to with waste scary new regular con of once br regular best gillian timon br of and and surface first of today br regular con newspaper and disgusting br as agree is group house br as action best also is highly storyline is definitely storyline story at of shoulder hours house not this radio film hours hong of hours per visiting harvey of on not think radio laughing house story transition of europe house movie running this verhoeven special of capturing cop know twist with and "
     ]
    }
   ],
   "source": [
    "for encoding in X_train[652]:\n",
    "  for key, value in word_index.items():\n",
    "    if encoding == value:\n",
    "      print(key, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjzyMYDpAx1F",
    "outputId": "231922f9-fbb1-475a-bd74-19baed6c8c1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[652]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4X0QynjBKhe"
   },
   "source": [
    "- we can notice that for the record in index 30 the label is 0 which is negative and we can clearly see the original encoding\n",
    "- For the record 652 the label is positive(1) which is shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrdFCWqDBole"
   },
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "W3xSupDlDM2V"
   },
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding Layer - Keras , Vocabulary size = 10000, dimension of the dense embedding = 100, length of the input sequence  = 300\n",
    "model.add(Embedding(input_dim = 10000, output_dim = 100, input_length = 300))\n",
    "\n",
    "# LSTM with return seqence True with activation function relu\n",
    "model.add(LSTM(64, activation = 'relu', return_sequences=True))\n",
    "\n",
    "# TimeDistributed with 100 dense neurons\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "\n",
    "# Flatten Layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "\n",
    "\n",
    "# last dense layer used sigmoid funtion for giving output o or 1\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIdqsK1RHjxW"
   },
   "source": [
    "### Compile The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rs7u31wEDkwk"
   },
   "outputs": [],
   "source": [
    "# optimier used adam, loss - binary cross etropy, accuracy is used as metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tU1WU1uH6Tt"
   },
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FSlP-vQDp1b",
    "outputId": "f211768f-6faf-4cbd-98e0-026f652bd94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300, 64)           42240     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 300, 100)          6500      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              30721024  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 32,426,149\n",
      "Trainable params: 32,426,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9j0qqxvI6SS"
   },
   "source": [
    "- relu is uded on the hidden layers\n",
    "- the units are fully connected because of dense layer\n",
    "- we use sigmoid on output layer which gives either 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muZj4Wx9Dsl0",
    "outputId": "7918c6a5-25fd-45e0-8d09-1f3068f74795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 256s 3s/step - loss: 0.6176 - accuracy: 0.6059 - val_loss: 0.3336 - val_accuracy: 0.8662\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 254s 3s/step - loss: 0.2006 - accuracy: 0.9248 - val_loss: 0.3020 - val_accuracy: 0.8805\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 255s 3s/step - loss: 0.1088 - accuracy: 0.9626 - val_loss: 0.3719 - val_accuracy: 0.8684\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 253s 3s/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.4969 - val_accuracy: 0.8648\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 256s 3s/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.6665 - val_accuracy: 0.8554\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 256s 3s/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.8542 - val_accuracy: 0.8621\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 255s 3s/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.9353 - val_accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 252s 3s/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.8625 - val_accuracy: 0.8590\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 254s 3s/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.9458 - val_accuracy: 0.8604\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 252s 3s/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 1.1915 - val_accuracy: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f702529cc50>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUi99xgdJUj3"
   },
   "source": [
    "- The model overfits on the third epoch and the validation accuracy drops after that.\n",
    "- The model will be good if we stop on epoch 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLSqrdr4UUTV"
   },
   "source": [
    "#### Evaluate The Above Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7i3wyX0UTlK",
    "outputId": "fa872123-f808-4d93-b81c-174d5b1ecd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 74s 95ms/step - loss: 1.1915 - accuracy: 0.8604\n"
     ]
    }
   ],
   "source": [
    "model_score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rshox7rbUgDF",
    "outputId": "c2c5959e-ea17-40be-b0fe-ef93ea12455f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of the model is :  1.191495418548584\n",
      "The Accuracy of the model is :  0.8604000210762024\n"
     ]
    }
   ],
   "source": [
    "print(\"The loss of the model is : \" , model_score[0])\n",
    "print(\"The Accuracy of the model is : \", model_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thyPuLCtVpjZ"
   },
   "source": [
    "- loss is very high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxYB9MpxJqJx"
   },
   "source": [
    "### Redefining The model again with same structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Scf25HB3DzWT"
   },
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model1 = Sequential()\n",
    "\n",
    "# Embedding Layer - Keras , Vocabulary size = 10000, dimension of the dense embedding = 100, length of the input sequence  = 300\n",
    "model1.add(Embedding(input_dim = 10000, output_dim = 100, input_length = 300))\n",
    "\n",
    "# LSTM with return seqence True with activation function relu\n",
    "model1.add(LSTM(64, activation = 'relu', return_sequences=True))\n",
    "\n",
    "# TimeDistributed with 100 dense neurons\n",
    "model1.add(TimeDistributed(Dense(100)))\n",
    "\n",
    "# Flatten Layer\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Dense Layer\n",
    "model1.add(Dense(1024, activation = 'relu'))\n",
    "model1.add(Dense(512, activation = 'relu'))\n",
    "model1.add(Dense(256, activation = 'relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kOZ8FxqWODT"
   },
   "source": [
    "#### Compile Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "-pyp4810WLco"
   },
   "outputs": [],
   "source": [
    "# optimier used adam, loss - binary cross etropy, accuracy is used as metrics\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhr1oJQwJ1XJ"
   },
   "source": [
    "### Summary of Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btgc5gf3JzRV",
    "outputId": "b3e0cf18-f136-4b85-f5e6-bac96882d292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 300, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 300, 64)           42240     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 300, 100)          6500      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              30721024  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 32,426,149\n",
      "Trainable params: 32,426,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmjmxaWMJ68y",
    "outputId": "f02beb38-7d06-4cc8-d911-2d02472ce52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "84/84 [==============================] - 256s 3s/step - loss: 0.5802 - accuracy: 0.6369 - val_loss: 0.2843 - val_accuracy: 0.8790\n",
      "Epoch 2/2\n",
      "84/84 [==============================] - 255s 3s/step - loss: 0.1969 - accuracy: 0.9267 - val_loss: 0.2960 - val_accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7025afcb10>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3Bu89Z8XyDq"
   },
   "source": [
    "- The above model is not overfitting hence 2 epochs is very good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUdsk5Q5VxVV"
   },
   "source": [
    "#### Evaluation of Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neKaMGaCVvf8",
    "outputId": "2a843b5c-2db9-4bb4-becc-e5cedea0a4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 74s 95ms/step - loss: 0.2960 - accuracy: 0.8767\n"
     ]
    }
   ],
   "source": [
    "model1_score = model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ibV6tQ9V32S",
    "outputId": "50bd5ce1-5312-4ff0-f4a5-4f3667c64307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of the model1 is :  0.2959861755371094\n",
      "The Accuracy of the model1 is :  0.8766800165176392\n"
     ]
    }
   ],
   "source": [
    "print(\"The loss of the model1 is : \" , model1_score[0])\n",
    "print(\"The Accuracy of the model1 is : \", model1_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63iQeh55e8ko"
   },
   "source": [
    "### Predict using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KrqYsQOfCwF",
    "outputId": "63f011ad-4f74-4d7b-f629-969c2457c674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9582788]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(X_test[30].reshape((1, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxycnEH9fffC",
    "outputId": "9b6fce8d-15a0-4ad1-bda1-6737772fb46f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXnmDgDWfWJP",
    "outputId": "c02c36ef-ac80-470b-8108-20358369639c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.7246295e-09]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[652].reshape((1, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ki6c2dqtfaOm",
    "outputId": "4dee9288-6e72-4fbf-e12b-4e7d7412cea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[652]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6wZlnZmfu1D"
   },
   "source": [
    "- The model is predicting well. \n",
    "- The above 2 samples of record 30 and 652 is predicted well in the test set and are accurate\n",
    "- our model has validation accuracy of 87% and train accuracy of 92% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWW2oNwrflSg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
